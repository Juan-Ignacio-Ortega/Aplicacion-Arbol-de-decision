{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DTADescription_JIOG.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Metodología"
      ],
      "metadata": {
        "id": "-TvsJSeOzMNM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recolección de datos"
      ],
      "metadata": {
        "id": "kUnLbI8fLkUK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importamos librerías necesarias durante le desarrollo del algoritmo."
      ],
      "metadata": {
        "id": "DAPlKonvL1ST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import math as mt\n",
        "import random as rd\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Q0BVO7X2LmiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accedemos a la carpeta de drive donde se encuentra la base de datos."
      ],
      "metadata": {
        "id": "eJFDR0vsL4U3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1rmK49Z5MB2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargamos la base de datos Drugs ABCXY, dentro de la variable 'DB'."
      ],
      "metadata": {
        "id": "z5EHB0DXBT5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DB = pd.read_csv('/content/drive/MyDrive/ML_TSIV/Examen_2/mushrooms.csv')"
      ],
      "metadata": {
        "id": "-bn2Vi6KNAVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dejamos estática la base de datos sin modificar procesos posteriores."
      ],
      "metadata": {
        "id": "BjCpS_Mn7G8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DB_STAY = DB"
      ],
      "metadata": {
        "id": "kSFKtvb87D8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Damos un primer vistazo a la base de datos, mostrando los datos organizados en una tabla."
      ],
      "metadata": {
        "id": "7WtY37L6Be50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DB.head()"
      ],
      "metadata": {
        "id": "OP2_fUdoNFFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Función para transformar cada atributo cualitativo dentro de la base de datos a datos numéricos."
      ],
      "metadata": {
        "id": "bM_iQykiClUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Cualit2Num(DBCN):\n",
        "  Titles = list(DBCN.columns)\n",
        "\n",
        "  Titles_str = []\n",
        "  for title in Titles:\n",
        "    if type(DBCN[title][0]) == str:\n",
        "      Titles_str.append(title)\n",
        "\n",
        "  for title in Titles_str:\n",
        "    types = pd.unique(DBCN[title])\n",
        "    i = 0\n",
        "    for data in types:\n",
        "      data_loc = np.where(DBCN[title] == data)[0]\n",
        "      for pos in data_loc:\n",
        "        DBCN[title][pos] = i\n",
        "      i += 1\n",
        "  return(DBCN)"
      ],
      "metadata": {
        "id": "n2QZIBH5w8XN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Llamamos a la función 'Cualit2Num' anterior para transformar la base de datos."
      ],
      "metadata": {
        "id": "wwBxbQDqDovz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DB = Cualit2Num(DB)\n",
        "DB.head()"
      ],
      "metadata": {
        "id": "V-mH6srXDBIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Posteriormente, desplegamos una representación gráfica de los datos, generando las relaciones entre cada atributo."
      ],
      "metadata": {
        "id": "2LA7W5QYL96e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(DB, vars = DB.columns[1:6], hue = DB.columns[0])"
      ],
      "metadata": {
        "id": "xaGjety8OP4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparación de los datos"
      ],
      "metadata": {
        "id": "KM4ylLHDPd-B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analizamos los datos de forma elemental."
      ],
      "metadata": {
        "id": "onSwrv4lo45b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculamos la cantidad de Atributos e Instancias."
      ],
      "metadata": {
        "id": "uKsTrE-akX9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NoAtributos = len(DB.T) - 1\n",
        "NoInstancias = len(DB)"
      ],
      "metadata": {
        "id": "NRDuzQ7tdbCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convertimos la base de datos en un arreglo."
      ],
      "metadata": {
        "id": "JwthNkUjTqwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DBar = DB.to_numpy()"
      ],
      "metadata": {
        "id": "q5SOgERUTW9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quitamos el atributo 16 debido a que cuenta con caracteríticas que son todas la misma, por lo tanto, no añadiría información relevante."
      ],
      "metadata": {
        "id": "AXcz37NIBnS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DBarnew = []\n",
        "for idx, element in enumerate(DBar.T):\n",
        "  if idx != 16:\n",
        "    DBarnew.append(element)\n",
        "\n",
        "DBarnew = np.array(DBarnew).T\n",
        "DBar = DBarnew"
      ],
      "metadata": {
        "id": "cQkiAh6G-dxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculamos el máximo y mínimo de cada Atributo."
      ],
      "metadata": {
        "id": "FQclTs0lTkwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MaximoDeAtributos = []\n",
        "MinimoDeAtributos = []\n",
        "for idx in range(NoAtributos):\n",
        "  CaractMax = max(DBar.T[idx])\n",
        "  CaractMin = min(DBar.T[idx])\n",
        "  MaximoDeAtributos.append(CaractMax)\n",
        "  MinimoDeAtributos.append(CaractMin)"
      ],
      "metadata": {
        "id": "kwJsFVkrTkRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculamos el primer y tercer cuartil (Q1 y Q3, respectivamente), de cada atributo."
      ],
      "metadata": {
        "id": "iGFP8cPBpFpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q1 = []\n",
        "Q3 = []\n",
        "for idx in range(NoAtributos):\n",
        "  if str(type(DBar[0][idx]))[8 : -2] != 'str':\n",
        "    atrib = DBar.T[idx].tolist()\n",
        "    atrib.sort()\n",
        "\n",
        "    NoCuartil1 = 0.25 * (NoInstancias + 1)\n",
        "    if str(type(NoCuartil1))[8 : -2] != 'int':\n",
        "      pos1 = round(NoCuartil1)\n",
        "      if pos1 < NoCuartil1:\n",
        "        pos2 = pos1 + 1\n",
        "      else:\n",
        "        pos2 = pos1 - 1\n",
        "      NoCuartil1 = round((pos1 + pos2) / 2)\n",
        "    Cuartil1 = atrib[NoCuartil1 + 1]\n",
        "    incremento = 1\n",
        "    while True:\n",
        "      if str(Cuartil1) == 'nan':\n",
        "          Cuartil1 = atrib[NoCuartil1]\n",
        "          NoCuartil1 -= 1\n",
        "      else:\n",
        "        break\n",
        "\n",
        "    NoCuartil3 = 0.7 * (NoInstancias + 1)\n",
        "    if str(type(NoCuartil3))[8 : -2] != 'int':\n",
        "      pos1 = round(NoCuartil3)\n",
        "      if pos1 < NoCuartil3:\n",
        "        pos2 = pos1 + 1\n",
        "      else:\n",
        "        pos2 = pos1 - 1\n",
        "      NoCuartil3 = round((pos1 + pos2) / 2)\n",
        "    Cuartil3 = atrib[NoCuartil3 + 1]\n",
        "    while True:\n",
        "      if str(Cuartil3) == 'nan':\n",
        "          Cuartil3 = atrib[NoCuartil3]\n",
        "          NoCuartil3 -= 1\n",
        "      else:\n",
        "        break\n",
        "\n",
        "  Q1.append(Cuartil1)\n",
        "  Q3.append(Cuartil3)\n",
        "Q1 = np.array(Q1)\n",
        "Q3 = np.array(Q3)"
      ],
      "metadata": {
        "id": "bo9by3bkpLXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Detectamos outliers y eliminamos sus respectivas instancias."
      ],
      "metadata": {
        "id": "T-SAYyUhotJo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculamos el rango intercuantílico de cada atributo."
      ],
      "metadata": {
        "id": "qAMGX4eYrfvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IQR = []\n",
        "for idx in range(len(Q1)):\n",
        "  IQR.append(Q3[idx] - Q1[idx])"
      ],
      "metadata": {
        "id": "kOetzPrHrKmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Buscamos valores atípicos y el atributo en el que se encuentra ese valor (Seleccionamos quitar solo outliers extremos con OutType = 3, o también leves con OutType = 1.5). "
      ],
      "metadata": {
        "id": "lr37VRS0vdkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OutType = 3\n",
        "\n",
        "Inst2Elim = []\n",
        "for idx, Atrib in enumerate(DBar.T):\n",
        "  probe1 = Q1[idx] - OutType * IQR[idx]\n",
        "  probe2 = Q3[idx] + OutType * IQR[idx]\n",
        "  for idx2, Val in enumerate(Atrib):\n",
        "    if ((Val < probe1) or (Val > probe2)) and (idx2 not in Inst2Elim):\n",
        "      Inst2Elim.append(idx2)"
      ],
      "metadata": {
        "id": "vt84MZGIri7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generamos una nuevo array de datos eliminando las instancias que contienen algún outlier."
      ],
      "metadata": {
        "id": "BHuRTC8L6gCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DBWO = []\n",
        "for InstNum in range(len(DBar)):\n",
        "  if InstNum not in Inst2Elim:\n",
        "    DBWO.append(DBar[InstNum])\n",
        "\n",
        "DBWOar = np.array(DBWO)"
      ],
      "metadata": {
        "id": "7FQEZT6B4Mao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Desplegamos los valores sin outliers, los cuales fueron identificados considerando el rango intercuartílico."
      ],
      "metadata": {
        "id": "0WoGwRSf6yRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "showDB = pd.DataFrame(DBWOar)\n",
        "sns.pairplot(showDB, vars = showDB.columns[1:6], hue = showDB.columns[0])"
      ],
      "metadata": {
        "id": "hm85XryKZydn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalizamos los datos"
      ],
      "metadata": {
        "id": "fBdx-w4Coovw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elegimos un rango de normalización entre 0 y 1."
      ],
      "metadata": {
        "id": "bwBgq2TtPiFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MaximoNormalizado = 1\n",
        "MinimoNormalizado = 0\n",
        "RangoNormalizado = MaximoNormalizado - MinimoNormalizado"
      ],
      "metadata": {
        "id": "09vLi9W1Twhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizamos los valores y obtenemos el nuevo arreglo de valores normalizados 'DBNar'."
      ],
      "metadata": {
        "id": "P9ZoFhCjT7xG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DBNorm = []\n",
        "for idx in range(NoAtributos):\n",
        "  \n",
        "  CaractNorm = []\n",
        "  if str(type(DBar[0][idx]))[8 : -2] != 'str':\n",
        "    \n",
        "    RangodeDatos = MaximoDeAtributos[idx] - MinimoDeAtributos[idx]\n",
        "    for idx2 in range(NoInstancias):\n",
        "\n",
        "      if str(DBar[idx2][idx]) != 'nan':\n",
        "        D = DBar[idx2][idx] - MinimoDeAtributos[idx]\n",
        "        DPct = D / RangodeDatos\n",
        "        dNorm = RangoNormalizado * DPct\n",
        "        Normalizado = MinimoNormalizado + dNorm\n",
        "        CaractNorm.append(Normalizado)\n",
        "      else:\n",
        "        CaractNorm.append(DBar[idx2][idx])\n",
        "  \n",
        "  else:\n",
        "    for idx2 in range(NoInstancias):\n",
        "      CaractNorm.append(DBar[idx2][idx])\n",
        "  \n",
        "  DBNorm.append(CaractNorm)\n",
        "\n",
        "DBNar = np.array(DBNorm)"
      ],
      "metadata": {
        "id": "K2KxJ6SmPqli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizamos una parte de la base de datos con los valores normalizados, para garantizar una correcta transformación."
      ],
      "metadata": {
        "id": "XLPfiMAsRjz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DBNarT = DBNar.T\n",
        "showDB = pd.DataFrame(DBNarT)\n",
        "showDB.head()"
      ],
      "metadata": {
        "id": "Brejl8imU4r7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### No. de datos faltantes por atributo"
      ],
      "metadata": {
        "id": "U-FcqUdsnGXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NoFaltantes = []\n",
        "ceros = 0\n",
        "for idx, element in enumerate(DBNarT.T):\n",
        "  sumatoria = 0\n",
        "  for idx2, element2 in enumerate(DBNarT):\n",
        "    if str(DBNarT.T[idx][idx2]) == 'nan':\n",
        "      sumatoria += 1\n",
        "  NoFaltantes.append(sumatoria)\n",
        "  \n",
        "  if sumatoria != 0:\n",
        "    print('La cantidad de carcaterísticas faltantes en el atributo', str(idx + 1), 'es igual a', str(sumatoria) + '.')\n",
        "  else:\n",
        "    ceros += 1\n",
        "  \n",
        "  if ceros == len(DBNarT.T):\n",
        "    print('No hay datos faltantes')"
      ],
      "metadata": {
        "id": "Wb9EgH2-k39E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análisis de los datos"
      ],
      "metadata": {
        "id": "lTpPPDKh791N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Serie de funciones creadas para obtener las métricas de rendimiento de un modelo."
      ],
      "metadata": {
        "id": "MuKGMuFLUBE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Función para obtener el error cuadrático medio, recibe las listas de los valores predichos y los valores reales.\n",
        "def MSE(MSEpred, MSEreal):\n",
        "  MSEpredN = []\n",
        "  for MSEp in MSEpred:\n",
        "    MSEpredN.append(MSEp/100)\n",
        "\n",
        "  MSErealN = []\n",
        "  for MSEr in MSEreal:\n",
        "    MSErealN.append(MSEr/100)\n",
        "  \n",
        "  MSEsize = len(MSErealN)\n",
        "  MSEt = 0\n",
        "  for MSEidx in range(MSEsize):\n",
        "    MSEt += (MSEpredN[MSEidx] - MSErealN[MSEidx])**2\n",
        "  MSEf = MSEt / MSEsize\n",
        "  return(MSEf)\n",
        "\n",
        "#Función para calcular la tasa de clasificación, recibe las listas de los valores predichos y los valores reales.\n",
        "def TC(TCpred, TCreal):\n",
        "  TCsize = len(TCpred)\n",
        "  TCt = 0\n",
        "  for TCidx in range(TCsize):\n",
        "    if TCpred[TCidx] != TCreal[TCidx]:\n",
        "      TCt += 1\n",
        "  TCf = 1 - TCt / TCsize\n",
        "  return(TCf)\n",
        "\n",
        "#Función que obtiene los valores de la matriz de confusión (TP, FN, FP, TN), recibe las listas de los valores predichos y los valores reales.\n",
        "def calculo_error(confusion_matrix):\n",
        "  FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)\n",
        "  FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
        "  TP = np.diag(confusion_matrix)\n",
        "  TN = confusion_matrix.sum() - (FP + FN + TP)\n",
        "\n",
        "  FP = min(FP)\n",
        "  FN = min(FN)\n",
        "  TP = min(TP)\n",
        "  TN = min(TN)\n",
        "  return (TP, FN, FP, TN)\n",
        "\n",
        "#Funciones para calcular la tasa de clasificación (TdC), incluyendo la exactitud (TdCExact), precisión (TdCPre), sensitividad o Recall (TdCSens)\n",
        "#y puntaje F - beta con beta = 1, es decir, F1 (TdCF1).\n",
        "def TdC(TdCTP, TdCFN, TdCFP, TdCTN):\n",
        "  TdCExact = (TdCTP + TdCTN) / (TdCTP + TdCTN + TdCFP + TdCFN)\n",
        "  TdCPre = TdCTP / (TdCTP + TdCFP)\n",
        "  TdCSens = TdCTP / (TdCTP + TdCFN)\n",
        "  TdCF1 = (2 * TdCTP) / (2 * TdCTP + TdCFP + TdCFN)\n",
        "  return([TdCExact, TdCPre, TdCSens, TdCF1])\n",
        "\n",
        "#Función para obtener las estadísticas de rendimiento, recibe las listas de los valores predichos y los valores reales.\n",
        "def Estadisticas(EYPred, EYreal):\n",
        "  EMSE = MSE(EYPred, EYreal)\n",
        "  ETC = TC(EYPred, EYreal)\n",
        "  CM = confusion_matrix(EYPred, EYreal)\n",
        "  ETP, EFN, EFP, ETN = calculo_error(CM)\n",
        "  EExact, EPrecis, ESens, EF1 = TdC(ETP, EFN, EFP, ETN)\n",
        "  Estadistica = [EMSE, ETC, EExact, EPrecis, ESens, EF1]\n",
        "  return(Estadistica)"
      ],
      "metadata": {
        "id": "WGvrfvYiT5VU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creación de una clase propia, la cual fungirá como un árbol de decisión usando el algoritmo de ID3."
      ],
      "metadata": {
        "id": "SlfcnVhf-Z6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTree_ID3():\n",
        "  def Entropia(self, YE):\n",
        "    YE = list(YE)\n",
        "    TotalE = len(YE)\n",
        "    TiposE = np.unique(YE)\n",
        "    ET = 0\n",
        "    for TipoE in TiposE:\n",
        "      PEi = YE.count(TipoE) / TotalE\n",
        "      ET -= PEi * mt.log2(PEi)\n",
        "    return(ET)\n",
        "\n",
        "  def Ganancia(self, EG, AtributoG, YG):\n",
        "    AtributoGarr = AtributoG\n",
        "    AtributoG = list(AtributoG)\n",
        "    TotalG = len(AtributoG)\n",
        "    TiposG = np.unique(AtributoG)\n",
        "    GT = EG\n",
        "    for TipoG in TiposG:\n",
        "      posG = np.where(AtributoGarr == TipoG)[0]\n",
        "      posG = np.unique(posG)\n",
        "      YGSel = []\n",
        "      for pG in posG:\n",
        "        YGSel.append(YG[pG])\n",
        "      PGi = AtributoG.count(TipoG) / TotalG\n",
        "      GT -= PGi * self.Entropia(YGSel)\n",
        "    return(GT)\n",
        "\n",
        "  def PRN(self, XRN, YRN):\n",
        "    SRN = self.Entropia(YRN)\n",
        "    GananciasRN = []\n",
        "    XRN = np.array(XRN)\n",
        "    for AtributoRN in XRN.T:\n",
        "      GananciasRN.append(self.Ganancia(SRN, AtributoRN, YRN))\n",
        "    Rmax = max(GananciasRN)\n",
        "    GananciasRN = np.array(GananciasRN)\n",
        "    PosR = np.where(GananciasRN == Rmax)[0][0]\n",
        "    return(PosR)\n",
        "\n",
        "  def FDataNRes(self, XFDNR, YFDNR, RootPosFDNR, RootFDNR, LeafsFDNR):#, YGFR):\n",
        "    XFDNRarr = np.array(XFDNR)\n",
        "    XnewFDNR =  []\n",
        "    for idxFDNR, AtribFDNR in enumerate(XFDNRarr.T):\n",
        "      if idxFDNR != RootPosFDNR:\n",
        "        AtribFDNR = list(AtribFDNR)\n",
        "        XnewFDNR.append(AtribFDNR)\n",
        "    XnewFDNR = np.array(XnewFDNR).T\n",
        "    XnewFDNR = XnewFDNR.tolist()\n",
        "\n",
        "    XOutFDNR = []\n",
        "    YOutFDNR = []\n",
        "    if len(XnewFDNR) != 0:\n",
        "      for LeafFDNR in LeafsFDNR:\n",
        "        PosLeaf = np.where(RootFDNR == LeafFDNR)[0]\n",
        "        X2Add = []\n",
        "        Y2Add = []\n",
        "        for idxFDNR in PosLeaf:\n",
        "          X2Add.append(XnewFDNR[idxFDNR])\n",
        "          Y2Add.append(YFDNR[idxFDNR])\n",
        "        XOutFDNR.append(X2Add)\n",
        "        YOutFDNR.append(Y2Add)\n",
        "\n",
        "    LeafResFDNR = []\n",
        "    LeafStatusFDNR = []\n",
        "    for YLeafFDNR in YOutFDNR:\n",
        "      CounterFDNR = Counter(YLeafFDNR)\n",
        "      FirstFR  = CounterFDNR.most_common(1)\n",
        "      LeafResFDNR.append(FirstFR[0][0])\n",
        "\n",
        "      if len(np.unique(YLeafFDNR)) == 1:\n",
        "        LeafStatusFDNR.append(1)\n",
        "      else:\n",
        "        LeafStatusFDNR.append(0)\n",
        "    return(XOutFDNR, YOutFDNR, LeafResFDNR, LeafStatusFDNR)\n",
        "\n",
        "  def FindRoot(self, XFR, YFR):\n",
        "    RootPosFR = self.PRN(XFR, YFR)\n",
        "    XFRarr = np.array(XFR)\n",
        "    Root = XFRarr.T[RootPosFR]\n",
        "    LeafsFR = np.unique(Root)\n",
        "    DataNRes = self.FDataNRes(XFR, YFR, RootPosFR, Root, LeafsFR)#, YGFR)\n",
        "    Data4LeafXFR = DataNRes[0]\n",
        "    Data4LeafYFR = DataNRes[1]\n",
        "    LeafsResultsFR = DataNRes[2]\n",
        "    LeafsStatusFR = DataNRes[3]\n",
        "    return(RootPosFR, LeafsFR, Data4LeafXFR, Data4LeafYFR, LeafsResultsFR, LeafsStatusFR)\n",
        "\n",
        "  def PredDato(self, XPD, DTPD):\n",
        "    ProfundidadPD = 0\n",
        "    RootPD = XPD[DTPD[0][ProfundidadPD][0]]\n",
        "    LeafsPD = DTPD[1][ProfundidadPD]\n",
        "    NextPosPD = np.where(LeafsPD == RootPD)[0][0]\n",
        "    Ypred = DTPD[4][ProfundidadPD][NextPosPD]\n",
        "    while (DTPD[5][ProfundidadPD][NextPosPD] != 1):\n",
        "      try:\n",
        "        ProfundidadPD += 1\n",
        "        RootPD = XPD[DTPD[0][ProfundidadPD][NextPosPD]]\n",
        "        LeafsPD = DTPD[1][ProfundidadPD][NextPosPD]\n",
        "        NextPosPD = np.where(LeafsPD == RootPD)[0][0]\n",
        "        Ypred = DTPD[4][ProfundidadPD][NextPosPD]\n",
        "      except:\n",
        "        break\n",
        "    return(Ypred)\n",
        "\n",
        "  def fit(self, Xtrainfit, Ytrainfit):\n",
        "    AtribQuantity = len(Xtrainfit.T)\n",
        "    RootRes = self.FindRoot(Xtrainfit, Ytrainfit)\n",
        "    RootPos = RootRes[0]\n",
        "    Leafs = RootRes[1]\n",
        "    Data4LeafX = RootRes[2]\n",
        "    Data4LeafY = RootRes[3]\n",
        "    LeafsResults = RootRes[4]\n",
        "    LeafsStatus = RootRes[5]\n",
        "    FinalStatus = len(np.unique(LeafsStatus))\n",
        "    UsedAtrib = 1\n",
        "    self.Profundidad = 0\n",
        "    self.DT = [[[RootPos]], [Leafs], [Data4LeafX], [Data4LeafY], [LeafsResults], [LeafsStatus]]\n",
        "    while (UsedAtrib != AtribQuantity) and (FinalStatus != 1):\n",
        "      self.Profundidad += 1\n",
        "      self.DT[0].append([])\n",
        "      for idx, Root in enumerate(self.DT[1][self.Profundidad-1]):\n",
        "        Xtemp = self.DT[2][self.Profundidad-1][idx]\n",
        "        Ytemp = self.DT[3][self.Profundidad-1][idx]\n",
        "        if self.DT[5][self.Profundidad-1][idx] != 1: \n",
        "          RootRes = self.FindRoot(Xtemp, Ytemp)\n",
        "          RootPos = RootRes[0]\n",
        "          Leafs = RootRes[1]\n",
        "          Data4LeafX = RootRes[2]\n",
        "          Data4LeafY = RootRes[3]\n",
        "          LeafsResults = RootRes[4]\n",
        "          LeafsStatus = RootRes[5]\n",
        "          self.DT[0][self.Profundidad].append(RootPos)\n",
        "          self.DT[1].append(Leafs)\n",
        "          self.DT[2].append(Data4LeafX)\n",
        "          self.DT[3].append(Data4LeafY)\n",
        "          self.DT[4].append(LeafsResults)\n",
        "          self.DT[5].append(LeafsStatus)\n",
        "          UsedAtrib += 1\n",
        "      FinalStatus = len(np.unique(self.DT[5][self.Profundidad]))\n",
        "\n",
        "  def GetPred(self, Datos):\n",
        "    Ypred = []\n",
        "    for data in Datos:\n",
        "      Ypred.append(self.PredDato(data, self.DT))\n",
        "    return(Ypred)"
      ],
      "metadata": {
        "id": "65mCLkPP00Yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamos un modelo con el algoritmo de KNN generado."
      ],
      "metadata": {
        "id": "jiRC_o30AA-h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generación de X e Y"
      ],
      "metadata": {
        "id": "jU6khg8Nb93W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agregamos aleatoriedad al orden de la base de datos."
      ],
      "metadata": {
        "id": "ailrcRRHb93X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RDBNar = rd.sample(DBNar.T.tolist(), k=len(DBNar.T))\n",
        "RDBNar = np.array(RDBNar).T"
      ],
      "metadata": {
        "id": "Ar5tn4-Ob93Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seleccionamos el atributo para nuestro valor objetivo 'Y' y el resto 'X' como ejemplos para el entrenamiento."
      ],
      "metadata": {
        "id": "u6ZDWOlNb93Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = DBNar[1:]\n",
        "X = X.T\n",
        "Y = DBNar[0]"
      ],
      "metadata": {
        "id": "pMCww5h5b93Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamos el modelo"
      ],
      "metadata": {
        "id": "svZqmla0VN-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Haremos 5 pruebas, eligiendo K=5 para el método de K-FOLD, en este caso, 5-FOLD."
      ],
      "metadata": {
        "id": "gsz8dH_T5gXn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La base de datos ya se encuentra ordenada aletaoriamente, por lo tanto solo tomaremos distintas secciones para el 20% de pruebas y su respectivo 80% para netrenamiento."
      ],
      "metadata": {
        "id": "l7Fa4XjP50Sq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hrpx_vwgpbp"
      },
      "source": [
        "Xres = X\n",
        "Yres = Y\n",
        "\n",
        "DBsize = len(Xres)\n",
        "DBp = DBsize / 5\n",
        "VDB = int(DBp)\n",
        "CDB = int(DBp * 2)\n",
        "SDB = int(DBp * 3)\n",
        "ODB = int(DBp * 4)\n",
        "\n",
        "Xtest1, Xtrain1, Ytest1, Ytrain1 = train_test_split(Xres, Yres, test_size = 0.80, shuffle = False)\n",
        "\n",
        "Xtrain2, Ytrain2 = Xres[:VDB].tolist() + Xres[CDB:].tolist(), Yres[:VDB].tolist() + Yres[CDB:].tolist()\n",
        "Xtrain2, Ytrain2 = np.array(Xtrain2), np.array(Ytrain2)\n",
        "Xtest2, Ytest2 = Xres[VDB:CDB], Yres[VDB:CDB]\n",
        "\n",
        "Xtrain3, Ytrain3 = Xres[:CDB].tolist() + Xres[SDB:].tolist(), Yres[:CDB].tolist() + Yres[SDB:].tolist()\n",
        "Xtrain3, Ytrain3 = np.array(Xtrain3), np.array(Ytrain3)\n",
        "Xtest3, Ytest3 = Xres[CDB:SDB], Yres[CDB:SDB]\n",
        "\n",
        "Xtrain4, Ytrain4 = Xres[:SDB].tolist() + Xres[ODB:].tolist(), Yres[:SDB].tolist() + Yres[ODB:].tolist()\n",
        "Xtrain4, Ytrain4 = np.array(Xtrain4), np.array(Ytrain4)\n",
        "Xtest4, Ytest4 = Xres[SDB:ODB], Yres[SDB:ODB]\n",
        "\n",
        "Xtrain5, Xtest5, Ytrain5, Ytest5 = train_test_split(Xres, Yres, test_size = 0.20, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamos con KNN cada uno de los 5 grupos de datos\n",
        "Nota: Es posible elegir qué métrica ('MSE', 'TdC', 'Exactitud', 'Precision', 'Recall' o 'F1') tomar como referencia, en este caso se elige 'Precision'."
      ],
      "metadata": {
        "id": "5YX-06H7i5F2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = DecisionTree_ID3()\n",
        "model1.fit(Xtrain1, Ytrain1)\n",
        "\n",
        "model2 = DecisionTree_ID3()\n",
        "model2.fit(Xtrain2, Ytrain2)\n",
        "\n",
        "model3 = DecisionTree_ID3()\n",
        "model3.fit(Xtrain3, Ytrain3)\n",
        "\n",
        "model4 = DecisionTree_ID3()\n",
        "model4.fit(Xtrain4, Ytrain4)\n",
        "\n",
        "model5 = DecisionTree_ID3()\n",
        "model5.fit(Xtrain5, Ytrain5)"
      ],
      "metadata": {
        "id": "f6Nud9b0jIMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determinamos las predicciones de cada modelo."
      ],
      "metadata": {
        "id": "UNm15ibjn5GX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Ymodel1Pred = model1.GetPred(Xtest1)\n",
        "TasCla1 = TC(Ymodel1Pred, Ytest1)\n",
        "\n",
        "Ymodel2Pred = model2.GetPred(Xtest2)\n",
        "TasCla2 = TC(Ymodel2Pred, Ytest2)\n",
        "\n",
        "Ymodel3Pred = model3.GetPred(Xtest3)\n",
        "TasCla3 = TC(Ymodel3Pred, Ytest3)\n",
        "\n",
        "Ymodel4Pred = model4.GetPred(Xtest4)\n",
        "TasCla4 = TC(Ymodel4Pred, Ytest4)\n",
        "\n",
        "Ymodel5Pred = model5.GetPred(Xtest5)\n",
        "TasCla5 = TC(Ymodel5Pred, Ytest5)\n",
        "\n",
        "StadisticFin = (TasCla1 + TasCla2 + TasCla3 + TasCla4 + TasCla5) / 5"
      ],
      "metadata": {
        "id": "W1BnlAtvbzM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Tasa de clasificación de la prueba 1 =', str(TasCla1) + '.')\n",
        "print('Tasa de clasificación de la prueba 2 =', str(TasCla2) + '.')\n",
        "print('Tasa de clasificación de la prueba 3 =', str(TasCla3) + '.')\n",
        "print('Tasa de clasificación de la prueba 4 =', str(TasCla4) + '.')\n",
        "print('Tasa de clasificación de la prueba 5 =', str(TasCla5) + '.')\n",
        "print('Precisión final =', str(StadisticFin) + '.')"
      ],
      "metadata": {
        "id": "463ctXyCbzxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluamos el modelo"
      ],
      "metadata": {
        "id": "xd02o0SAALzW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analizamos métricas de evaluación"
      ],
      "metadata": {
        "id": "4MezwzihAcLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tranformamos los datos de las etiquetas a enteros."
      ],
      "metadata": {
        "id": "yZTA5n2ZzdwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Yt1 = []\n",
        "for Ytt1 in Ytest1:\n",
        "  Yt1.append(int(Ytt1*100))\n",
        "\n",
        "Yt2 = []\n",
        "for Ytt2 in Ytest2:\n",
        "  Yt2.append(int(Ytt2*100))\n",
        "\n",
        "Yt3 = []\n",
        "for Ytt3 in Ytest3:\n",
        "  Yt3.append(int(Ytt3*100))\n",
        "\n",
        "Yt4 = []\n",
        "for Ytt4 in Ytest4:\n",
        "  Yt4.append(int(Ytt4*100))\n",
        "\n",
        "Yt5 = []\n",
        "for Ytt5 in Ytest5:\n",
        "  Yt5.append(int(Ytt5*100))\n",
        "\n",
        "Ytp1 = []\n",
        "for Yttp1 in Ymodel1Pred:\n",
        "  Ytp1.append(int(Yttp1*100))\n",
        "\n",
        "Ytp2 = []\n",
        "for Yttp2 in Ymodel2Pred:\n",
        "  Ytp2.append(int(Yttp2*100))\n",
        "\n",
        "Ytp3 = []\n",
        "for Yttp3 in Ymodel3Pred:\n",
        "  Ytp3.append(int(Yttp3*100))\n",
        "\n",
        "Ytp4 = []\n",
        "for Yttp4 in Ymodel4Pred:\n",
        "  Ytp4.append(int(Yttp4*100))\n",
        "\n",
        "Ytp5 = []\n",
        "for Yttp5 in Ymodel5Pred:\n",
        "  Ytp5.append(int(Yttp5*100))\n",
        "\n",
        "print(len(Yt1))\n",
        "print(len(Ytp2))"
      ],
      "metadata": {
        "id": "-UUqpGTRtm4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generamos la tabla de métricas."
      ],
      "metadata": {
        "id": "u4bGLCj33ccp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "ModelStatistics = Estadisticas(Ytp1, Yt1)\n",
        "\n",
        "STable = [ ['MSE', str(ModelStatistics[0])],\n",
        "     ['Tasa de clasificación', str(ModelStatistics[1])],\n",
        "     ['Exactitud', str(ModelStatistics[2])],\n",
        "     ['Precisión', str(ModelStatistics[3])],\n",
        "     ['Recall', str(ModelStatistics[4])],\n",
        "     ['F1', str(ModelStatistics[5])] ]\n",
        "\n",
        "print(tabulate(STable, headers = ['Métrica modelo 1', 'Valor'], tablefmt=\"presto\"))\n",
        "\n",
        "ModelStatistics = Estadisticas(Ytp2, Yt2)\n",
        "\n",
        "STable = [ ['MSE', str(ModelStatistics[0])],\n",
        "     ['Tasa de clasificación', str(ModelStatistics[1])],\n",
        "     ['Exactitud', str(ModelStatistics[2])],\n",
        "     ['Precisión', str(ModelStatistics[3])],\n",
        "     ['Recall', str(ModelStatistics[4])],\n",
        "     ['F1', str(ModelStatistics[5])] ]\n",
        "\n",
        "print(tabulate(STable, headers = ['Métrica modelo 2', 'Valor'], tablefmt=\"presto\"))\n",
        "\n",
        "ModelStatistics = Estadisticas(Ytp3, Yt3)\n",
        "\n",
        "STable = [ ['MSE', str(ModelStatistics[0])],\n",
        "     ['Tasa de clasificación', str(ModelStatistics[1])],\n",
        "     ['Exactitud', str(ModelStatistics[2])],\n",
        "     ['Precisión', str(ModelStatistics[3])],\n",
        "     ['Recall', str(ModelStatistics[4])],\n",
        "     ['F1', str(ModelStatistics[5])] ]\n",
        "\n",
        "print(tabulate(STable, headers = ['Métrica modelo 3', 'Valor'], tablefmt=\"presto\"))\n",
        "\n",
        "ModelStatistics = Estadisticas(Ytp4, Yt4)\n",
        "\n",
        "STable = [ ['MSE', str(ModelStatistics[0])],\n",
        "     ['Tasa de clasificación', str(ModelStatistics[1])],\n",
        "     ['Exactitud', str(ModelStatistics[2])],\n",
        "     ['Precisión', str(ModelStatistics[3])],\n",
        "     ['Recall', str(ModelStatistics[4])],\n",
        "     ['F1', str(ModelStatistics[5])] ]\n",
        "\n",
        "print(tabulate(STable, headers = ['Métrica modelo 4', 'Valor'], tablefmt=\"presto\"))\n",
        "\n",
        "ModelStatistics = Estadisticas(Ytp5, Yt5)\n",
        "\n",
        "STable = [ ['MSE', str(ModelStatistics[0])],\n",
        "     ['Tasa de clasificación', str(ModelStatistics[1])],\n",
        "     ['Exactitud', str(ModelStatistics[2])],\n",
        "     ['Precisión', str(ModelStatistics[3])],\n",
        "     ['Recall', str(ModelStatistics[4])],\n",
        "     ['F1', str(ModelStatistics[5])] ]\n",
        "\n",
        "print(tabulate(STable, headers = ['Métrica modelo 5', 'Valor'], tablefmt=\"presto\"))"
      ],
      "metadata": {
        "id": "009H9RJn6mLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtenemos la matriz de confusión de los datos de validación."
      ],
      "metadata": {
        "id": "JwE70cUS6IER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def confusionMatrix(y_data_test, y_pred_test, titleChart, columns):\n",
        "  cm = confusion_matrix(y_data_test, y_pred_test)\n",
        "  cm=pd.DataFrame(cm, index=columns, columns=columns)\n",
        "  plt.figure(figsize = (5,5))\n",
        "  plt.title(titleChart)\n",
        "  sns.heatmap(cm, annot = True,fmt=\"d\", cmap='Blues' ,annot_kws={\"size\": 12})\n",
        "  plt.show()\n",
        "\n",
        "print('Matriz de confusión de la prueba 1\\n')\n",
        "confusionMatrix(Ytp1, Yt1, 'Matriz de confusión', list(np.unique(DB_STAY['class'])))\n",
        "print('\\n\\nMatriz de confusión de la prueba 2\\n')\n",
        "confusionMatrix(Ytp2, Yt2, 'Matriz de confusión', list(np.unique(DB_STAY['class'])))\n",
        "print('\\n\\nMatriz de confusión de la prueba 3\\n')\n",
        "confusionMatrix(Ytp3, Yt3, 'Matriz de confusión', list(np.unique(DB_STAY['class'])))\n",
        "print('\\n\\nMatriz de confusión de la prueba 4\\n')\n",
        "confusionMatrix(Ytp4, Yt4, 'Matriz de confusión', list(np.unique(DB_STAY['class'])))\n",
        "print('\\n\\nMatriz de confusión de la prueba 5\\n')\n",
        "confusionMatrix(Ytp5, Yt5, 'Matriz de confusión', list(np.unique(DB_STAY['class'])))"
      ],
      "metadata": {
        "id": "JuLTOdVl14Id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, usaremos el intervalo de confianza Z para obtener los valores entre los que se encontraría la tasa de clasificación global."
      ],
      "metadata": {
        "id": "nOBqB2_0F_fF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def media(Nums):\n",
        "  n = len(Nums)\n",
        "  Suma = 0\n",
        "  for Num in Nums:\n",
        "    Suma += Num\n",
        "  ResM = Suma/n\n",
        "  return(ResM)\n",
        "\n",
        "def DesvEst(Nums):\n",
        "  n = len(Nums)\n",
        "  med = media(Nums)\n",
        "  Suma = 0\n",
        "  for Num in Nums:\n",
        "    Suma += (Num - med)**2\n",
        "  ResDE = (Suma / n)**0.5\n",
        "  return(ResDE)\n",
        "\n",
        "Cant_Pruebas = 50\n",
        "TCs = []\n",
        "for n in range(Cant_Pruebas):\n",
        "  model = DecisionTree_ID3()\n",
        "  model.fit(Xtrain1, Ytrain1)\n",
        "  YmodelPred = model.GetPred(Xtest1)\n",
        "  TasCla = TC(YmodelPred, Ytest1)\n",
        "  TCs.append(TasCla)\n",
        "\n",
        "MediaTC = media(TCs)\n",
        "DesvEstTC = DesvEst(TCs)\n",
        "\n",
        "Z = 1.96\n",
        "\n",
        "RangoError = Z*(DesvEstTC/(Cant_Pruebas)**0.5)\n",
        "\n",
        "print('Elegimos un valor de Z = 1.96 para un intervalo de confianza de 95%, logrando así un valor global de tasa de clasifciacion =', str(round(MediaTC, 4)), ' y un intervalo de confianza de', str(RangoError) + '.')\n",
        "print('\\nLo anterior quiere decir, que el valor real de Tasa de clasificación está entre', str(MediaTC - RangoError), 'y', str(MediaTC + RangoError) + '.')"
      ],
      "metadata": {
        "id": "P8ZEJmcd6uMT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}